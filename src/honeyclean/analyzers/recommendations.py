"""
Generate intelligent data cleaning recommendations.
"""

import pandas as pd
from typing import Dict, Any, List


class DataCleaningRecommendations:
    """Generate intelligent data cleaning recommendations.  ç”Ÿæˆæ™ºèƒ½æ•°æ®æ¸…æ´—å»ºè®®ã€‚"""

    @staticmethod
    def get_numeric_recommendations(analysis: Dict[str, Any]) -> List[str]:
        """Get cleaning recommendations for numeric columns. è·å–æ•°å€¼åˆ—çš„æ¸…æ´—å»ºè®®ã€‚"""
        recommendations = []

        # Check if analysis has error
        if "error" in analysis:
            zh = f"åˆ†æé”™è¯¯: {analysis['error']}"
            en = f"Analysis error: {analysis['error']}"
            recommendations.append((zh, en))
            return recommendations

        # Missing values - use .get() with default value
        missing_pct = analysis.get("missing_percentage", 0)
        if missing_pct > 5:
            zh = f"ğŸ” é«˜ç¼ºå¤±å€¼ ({missing_pct:.1f}%)ï¼Œå»ºè®®ä½¿ç”¨ä¸­ä½æ•°æ’å€¼æˆ–é«˜çº§æ–¹æ³•è¿›è¡Œå¤„ç†"
            en = f"ğŸ” High missing values ({missing_pct:.1f}%). Consider imputation with median or advanced methods."
            recommendations.append((zh, en))

        # Outliers
        zscore_outliers = analysis.get("zscore_outliers", 0)
        if zscore_outliers > 0:
            zh = f"âš ï¸ ä½¿ç”¨Z-scoreæ–¹æ³•å‘ç° {zscore_outliers} ä¸ªå¼‚å¸¸å€¼ï¼Œå»ºè®®è¿›è¡Œè°ƒæŸ¥æˆ–åˆ é™¤å¤„ç†"
            en = f"âš ï¸ Found {zscore_outliers} outliers using Z-score method. Consider investigation or removal."
            recommendations.append((zh, en))

        iqr_outliers = analysis.get("iqr_outliers", 0)
        if iqr_outliers > 0:
            zh = f"ğŸ“Š ä½¿ç”¨IQRæ–¹æ³•å‘ç° {iqr_outliers} ä¸ªå¼‚å¸¸å€¼ï¼Œå»ºè®®è¿›è¡Œç¼©å°¾å¤„ç†æˆ–è½¬æ¢"
            en = f"ğŸ“Š Found {iqr_outliers} outliers using IQR method. Consider winsorization or transformation."
            recommendations.append((zh, en))

        # Skewness
        skewness = analysis.get("skewness", 0)
        if abs(skewness) > 2:
            zh = f"ğŸ“ˆ é«˜ååº¦ ({skewness:.2f})ï¼Œå»ºè®®è¿›è¡Œå¯¹æ•°å˜æ¢æˆ–Box-Coxå˜æ¢"
            en = f"ğŸ“ˆ High skewness ({skewness:.2f}). Consider log transformation or Box-Cox transformation."
            recommendations.append((zh, en))

        # Distribution
        if not analysis.get("is_normal", True):
            zh = "ğŸ“‰ æ•°æ®éæ­£æ€åˆ†å¸ƒï¼Œå‚æ•°æ£€éªŒæ—¶å»ºè®®è¿›è¡Œå˜æ¢å¤„ç†"
            en = "ğŸ“‰ Data is not normally distributed. Consider transformation for parametric tests."
            recommendations.append((zh, en))

        # High coefficient of variation
        cv = analysis.get("coefficient_of_variation", 0)
        if cv > 1:
            zh = f"ğŸ“Š é«˜å˜å¼‚æ€§ (CV = {cv:.2f})ï¼Œå»ºè®®è¿›è¡Œæ ‡å‡†åŒ–æˆ–å½’ä¸€åŒ–å¤„ç†"
            en = f"ğŸ“Š High variability (CV = {cv:.2f}). Consider normalization or standardization."
            recommendations.append((zh, en))

        return recommendations

    @staticmethod
    def get_categorical_recommendations(analysis: Dict[str, Any]) -> List[str]:
        """Get cleaning recommendations for categorical columns.
        è·å–åˆ†ç±»åˆ—çš„æ¸…æ´—å»ºè®®
        Returns list of (chinese, english) tuples
        """
        recommendations = []

        # Check if analysis has error
        if "error" in analysis:
            zh = f"åˆ†æé”™è¯¯: {analysis['error']}"
            en = f"Analysis error: {analysis['error']}"
            recommendations.append((zh, en))
            return recommendations

        # Missing values
        missing_pct = analysis.get("missing_percentage", 0)
        if missing_pct > 5:
            zh = f"ğŸ” é«˜ç¼ºå¤±å€¼ ({missing_pct:.1f}%)ï¼Œå»ºè®®åˆ›å»º'æœªçŸ¥'ç±»åˆ«æˆ–ä½¿ç”¨ä¼—æ•°å¡«å……"
            en = f"ğŸ” High missing values ({missing_pct:.1f}%). Consider creating 'Unknown' category or mode imputation."
            recommendations.append((zh, en))

        # High cardinality
        if analysis.get("is_high_cardinality", False):
            unique_count = analysis.get("unique_count", 0)
            zh = f"ğŸ“Š é«˜åŸºæ•° ({unique_count} ä¸ªå”¯ä¸€å€¼)ï¼Œå»ºè®®å¯¹ç¨€æœ‰ç±»åˆ«è¿›è¡Œåˆ†ç»„æˆ–ä½¿ç”¨ç›®æ ‡ç¼–ç "
            en = f"ğŸ“Š High cardinality ({unique_count} unique values). Consider grouping rare categories or target encoding."
            recommendations.append((zh, en))

        # Rare categories
        rare_categories = analysis.get("rare_categories", [])
        if rare_categories:
            zh = f"ğŸ·ï¸ å‘ç° {len(rare_categories)} ä¸ªç¨€æœ‰ç±»åˆ«ï¼Œå»ºè®®åˆ†ç»„ä¸º'å…¶ä»–'ç±»åˆ«"
            en = f"ğŸ·ï¸ Found {len(rare_categories)} rare categories. Consider grouping into 'Other' category."
            recommendations.append((zh, en))

        # Imbalanced categories
        value_counts = analysis.get("value_counts", {})
        if value_counts and len(value_counts) > 1:
            max_count = max(value_counts.values())
            min_count = min(value_counts.values())
            if max_count / min_count > 10:
                zh = "âš–ï¸ ç±»åˆ«é«˜åº¦ä¸å¹³è¡¡ï¼Œå»ºæ¨¡æ—¶å»ºè®®è€ƒè™‘é‡é‡‡æ ·æˆ–åŠ æƒå¤„ç†"
                en = "âš–ï¸ Highly imbalanced categories. Consider resampling or weighting for modeling."
                recommendations.append((zh, en))

        return recommendations

    @staticmethod
    def get_datetime_recommendations(analysis: Dict[str, Any]) -> List[str]:
        """Get cleaning recommendations for datetime columns. è·å–æ—¥æœŸæ—¶é—´åˆ—çš„æ¸…æ´—å»ºè®®ã€‚"""
        recommendations = []

        # Check if analysis has error
        if "error" in analysis:
            zh = f"åˆ†æé”™è¯¯: {analysis['error']}"
            en = f"Analysis error: {analysis['error']}"
            recommendations.append((zh, en))
            return recommendations

        # Missing values
        missing_pct = analysis.get("missing_percentage", 0)
        if missing_pct > 5:
            zh = f"ğŸ” é«˜ç¼ºå¤±å€¼ ({missing_pct:.1f}%)ï¼Œå»ºè®®ä½¿ç”¨å‰å‘å¡«å……æˆ–æ’å€¼å¤„ç†"
            en = f"ğŸ” High missing values ({missing_pct:.1f}%). Consider forward-fill or interpolation."
            recommendations.append((zh, en))

        # Date range
        year_range = analysis.get("year_range", 0)
        if year_range > 50:
            zh = "ğŸ“… æ—¥æœŸèŒƒå›´è¿‡å®½ï¼Œè¯·éªŒè¯æ‰€æœ‰æ—¥æœŸçš„æœ‰æ•ˆæ€§å¹¶è€ƒè™‘è¿‡æ»¤å¼‚å¸¸å€¼"
            en = "ğŸ“… Wide date range. Verify if all dates are valid and consider filtering outliers."
            recommendations.append((zh, en))

        # Feature extraction
        zh = "ğŸ”§ å»ºè®®æå–ç‰¹å¾ï¼šå¹´ã€æœˆã€æ—¥ã€æ˜ŸæœŸã€å­£èŠ‚ã€å­£åº¦"
        en = "ğŸ”§ Consider extracting features: year, month, day, weekday, season, quarter."
        recommendations.append((zh, en))

        return recommendations

    @staticmethod
    def get_general_recommendations(df: pd.DataFrame) -> List[str]:
        """Get general dataset recommendations."""
        recommendations = []

        try:
            # Dataset size
            if len(df) < 100:
                zh = "ğŸ“ æ•°æ®é›†è¾ƒå°ï¼Œå»ºè®®æ”¶é›†æ›´å¤šæ•°æ®ä»¥è¿›è¡Œç¨³å¥åˆ†æ"
                en = "ğŸ“ Small dataset. Consider collecting more data for robust analysis."
            elif len(df) > 1000000:
                zh = "ğŸ“Š å¤§æ•°æ®é›†ï¼Œå»ºè®®ä½¿ç”¨é‡‡æ ·æˆ–åˆ†å—å¤„ç†ä»¥æé«˜å†…å­˜æ•ˆç‡"
                en = "ğŸ“Š Large dataset. Consider sampling or chunking for memory efficiency."
                recommendations.append((zh, en))

            # Memory usage
            memory_mb = df.memory_usage(deep=True).sum() / 1024 / 1024
            if memory_mb > 1000:
                zh = f"ğŸ’¾ é«˜å†…å­˜ä½¿ç”¨ ({memory_mb:.1f} MB)ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®ç±»å‹æˆ–åˆ†å—å¤„ç†"
                en = f"ğŸ’¾ High memory usage ({memory_mb:.1f} MB). Consider optimizing data types or processing in chunks."
                recommendations.append((zh, en))

            # Duplicate rows
            duplicate_count = df.duplicated().sum()
            if duplicate_count > 0:
                zh = f"ğŸ”„ å‘ç° {duplicate_count} ä¸ªé‡å¤è¡Œï¼Œå»ºè®®åˆ é™¤é‡å¤æ•°æ®"
                en = f"ğŸ”„ Found {duplicate_count} duplicate rows. Consider removing duplicates."
                recommendations.append((zh, en))

        except Exception as e:
            zh = f"å¸¸è§„åˆ†æé”™è¯¯: {str(e)}"
            en = f"Error in general analysis: {str(e)}"
            recommendations.append((zh, en))

        return recommendations
