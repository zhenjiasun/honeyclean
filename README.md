# HoneyClean ğŸ¯ (èœ‚èœœæ¸…æ´)

**Automated Data Profiling and Cleaning Package (è‡ªåŠ¨åŒ–æ•°æ®åˆ†æå’Œæ¸…æ´—åŒ…)**

HoneyClean is a comprehensive Python package for automated data profiling, cleaning recommendations, and professional report generation. It provides intelligent analysis of datasets with actionable insights for data scientists and analysts.

HoneyClean æ˜¯ä¸€ä¸ªå…¨é¢çš„ Python åŒ…ï¼Œç”¨äºè‡ªåŠ¨åŒ–æ•°æ®åˆ†æã€æ¸…æ´—å»ºè®®å’Œä¸“ä¸šæŠ¥å‘Šç”Ÿæˆã€‚å®ƒä¸ºæ•°æ®ç§‘å­¦å®¶å’Œåˆ†æå¸ˆæä¾›æ™ºèƒ½çš„æ•°æ®é›†åˆ†æå’Œå¯è¡Œçš„æ´å¯Ÿã€‚

## âœ¨ Features (åŠŸèƒ½ç‰¹æ€§)

### ğŸ” **Comprehensive Data Analysis (å…¨é¢æ•°æ®åˆ†æ)**
- **Automatic type detection (è‡ªåŠ¨ç±»å‹æ£€æµ‹)**: Smart inference of numeric, categorical, datetime, and text data types
- **Statistical analysis (ç»Ÿè®¡åˆ†æ)**: Comprehensive statistics including distribution analysis, outlier detection, and correlation analysis
- **Missing value analysis (ç¼ºå¤±å€¼åˆ†æ)**: Detailed missing data patterns and recommendations
- **Duplicate detection (é‡å¤æ£€æµ‹)**: Identification of duplicate rows and values

### ğŸ¯ **Target Variable Analysis (ç›®æ ‡å˜é‡åˆ†æ)**
- **Correlation analysis (ç›¸å…³æ€§åˆ†æ)**: Feature-target correlation with strength interpretation
- **Target distribution (ç›®æ ‡åˆ†å¸ƒ)**: Analysis of target variable distribution patterns
- **Categorical cross-analysis (åˆ†ç±»äº¤å‰åˆ†æ)**: Category distribution by target values
- **Multiple target support (å¤šç›®æ ‡æ”¯æŒ)**: Handle multiple target variables simultaneously

### ğŸ†” **ID Column Validation (IDåˆ—éªŒè¯)**
- **Uniqueness checking (å”¯ä¸€æ€§æ£€æŸ¥)**: Validate ID column uniqueness
- **Composite ID support (å¤åˆIDæ”¯æŒ)**: Multi-column ID validation
- **Duplicate detection (é‡å¤æ£€æµ‹)**: Identify and report duplicate ID values

### ğŸ“Š **Enhanced Formatting (å¢å¼ºæ ¼å¼åŒ–)**
- **Bilingual output (åŒè¯­è¾“å‡º)**: English and Chinese labels in all reports
- **Table formatting (è¡¨æ ¼æ ¼å¼åŒ–)**: Clean, readable statistical tables
- **Professional styling (ä¸“ä¸šæ ·å¼)**: Well-organized output with clear sections

### ğŸ“‹ **Intelligent Recommendations (æ™ºèƒ½å»ºè®®)**
- **Type-specific suggestions (ç±»å‹ç‰¹å®šå»ºè®®)**: Customized cleaning recommendations for each data type
- **Actionable insights (å¯æ‰§è¡Œæ´å¯Ÿ)**: Practical data quality improvement suggestions
- **Priority-based recommendations (ä¼˜å…ˆçº§å»ºè®®)**: Ranked suggestions by importance

### ğŸ“‘ **Professional Reports (ä¸“ä¸šæŠ¥å‘Š)**
- **PowerPoint generation (PowerPointç”Ÿæˆ)**: Automated creation of presentation-ready reports
- **JSON exports (JSONå¯¼å‡º)**: Machine-readable analysis results
- **CSV summaries (CSVæ‘˜è¦)**: Quick overview tables
- **Chinese language support (ä¸­æ–‡æ”¯æŒ)**: Full Chinese interface in reports

### âš™ï¸ **Configurable & Flexible (å¯é…ç½®å’Œçµæ´»)**
- **TOML configuration (TOMLé…ç½®)**: Easy-to-edit configuration files
- **Command-line interface (å‘½ä»¤è¡Œç•Œé¢)**: User-friendly CLI tools
- **Jupyter integration (Jupyteré›†æˆ)**: Seamless notebook support

## ğŸš€ Quick Start (å¿«é€Ÿå¼€å§‹)

### 1. Installation (å®‰è£…)

```bash
# Clone the repository (å…‹éš†ä»“åº“)
git clone https://github.com/honeyclean/honeyclean.git
cd honeyclean

# Install package (å®‰è£…åŒ…)
pip install -e .
```

### 2. Initialize Configuration (åˆå§‹åŒ–é…ç½®)

```bash
# Create configuration file (åˆ›å»ºé…ç½®æ–‡ä»¶)
honeyclean init

# This creates base.toml with default settings
# è¿™å°†åˆ›å»ºåŒ…å«é»˜è®¤è®¾ç½®çš„ base.toml æ–‡ä»¶
```

### 3. Configure Your Analysis (é…ç½®æ‚¨çš„åˆ†æ)

Edit `base.toml` to customize your analysis settings (ç¼–è¾‘ `base.toml` æ¥è‡ªå®šä¹‰åˆ†æè®¾ç½®):

```toml
[honeyclean]
version = "1.0.0"
description = "Automated data profiling and cleaning recommendations"

[paths]
# Set your data file path (è®¾ç½®æ•°æ®æ–‡ä»¶è·¯å¾„)
input_data = "./your_data.csv"
# Set output directory (è®¾ç½®è¾“å‡ºç›®å½•)
output_reports = "./reports"

[analysis]
chunk_size = 10000
max_memory_mb = 1024
enable_statistical_analysis = true
enable_outlier_detection = true
enable_correlation_analysis = true
enable_distribution_analysis = true

[thresholds]
outlier_threshold = 3.0
correlation_threshold = 0.8
high_cardinality_threshold = 50
missing_value_threshold = 0.05

[columns]
# IMPORTANT: Configure these for enhanced analysis
# é‡è¦ï¼šé…ç½®è¿™äº›ä»¥è¿›è¡Œå¢å¼ºåˆ†æ

# Target column(s) for correlation analysis (ç›®æ ‡åˆ—ç”¨äºç›¸å…³æ€§åˆ†æ)
# Single target: target_col = "sales_amount"
# Multiple targets: target_col = ["target1", "target2"]
target_col = "your_target_column"

# ID columns for uniqueness checking (ç”¨äºå”¯ä¸€æ€§æ£€æŸ¥çš„IDåˆ—)
# id_cols = ["user_id", "transaction_id", "product_id"]
id_cols = ["your_id_column"]

[visualization]
figure_dpi = 300
figure_width = 12
figure_height = 8
color_palette = "husl"

[output]
generate_html = true
generate_json = true
generate_powerpoint = true
generate_csv_summary = true

[logging]
level = "INFO"
format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
file = "honeyclean.log"
```

### 4. Run Analysis (è¿è¡Œåˆ†æ)

**Simple one-command analysis (ç®€å•ä¸€å‘½ä»¤åˆ†æ):**
```bash
# Complete analysis using config file settings (ä½¿ç”¨é…ç½®æ–‡ä»¶è®¾ç½®çš„å®Œæ•´åˆ†æ)
honeyclean run

# Override settings if needed (éœ€è¦æ—¶è¦†ç›–è®¾ç½®)
honeyclean run --sample 10000 --output ./custom_reports
```

**Individual commands (å•ç‹¬å‘½ä»¤):**
```bash
# Basic profiling with reports (åŸºç¡€åˆ†æå’ŒæŠ¥å‘Š)
honeyclean profile  # Uses config file
honeyclean profile your_data.csv  # Override with specific file

# Enhanced statistical display (å¢å¼ºç»Ÿè®¡æ˜¾ç¤º)  
honeyclean stats  # Uses config file
honeyclean stats your_data.csv --target-col sales_amount

# Analyze specific columns only (ä»…åˆ†æç‰¹å®šåˆ—)
honeyclean analyze your_data.csv --columns col1 --columns col2

# Sample large datasets (å¯¹å¤§æ•°æ®é›†é‡‡æ ·)
honeyclean run --sample 10000
```

## ğŸ“– Command Reference (å‘½ä»¤å‚è€ƒ)

### `honeyclean init`
Create a new configuration file (åˆ›å»ºæ–°çš„é…ç½®æ–‡ä»¶)
```bash
honeyclean init                    # Create base.toml
honeyclean init --config my.toml   # Custom config file name
honeyclean init --force            # Overwrite existing config
```

### `honeyclean run` â­ **RECOMMENDED**
Complete analysis in one command (ä¸€é”®å®Œæ•´åˆ†æ)
```bash
honeyclean run                     # Uses config file settings
honeyclean run data.csv            # Override input file
honeyclean run --sample 5000       # Sample large datasets
honeyclean run --output ./reports  # Custom output directory
honeyclean run --no-show-stats     # Skip detailed stats display
```

### `honeyclean profile`
Dataset profiling with report generation (æ•°æ®é›†åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ)
```bash
honeyclean profile                 # Uses config file
honeyclean profile data.csv        # Override input file
honeyclean profile --format json   # Specific output format
honeyclean profile --sample 5000   # Sample large datasets
```

### `honeyclean stats`
Enhanced statistical analysis with embedded reports (å¢å¼ºç»Ÿè®¡åˆ†æå’ŒåµŒå…¥å¼æŠ¥å‘Š)
```bash
honeyclean stats                   # Generate reports with embedded stats
honeyclean stats --console         # Also display stats in terminal
honeyclean stats data.csv --target-col revenue --id-cols user_id
honeyclean stats --output ./reports # Custom output directory
```

### `honeyclean analyze`
Detailed column-specific analysis (è¯¦ç»†çš„åˆ—ç‰¹å®šåˆ†æ)
```bash
honeyclean analyze data.csv --columns price --columns quantity
honeyclean analyze data.csv --output ./column_analysis
```

### `honeyclean info`
Display current configuration (æ˜¾ç¤ºå½“å‰é…ç½®)
```bash
honeyclean info
```

## ğŸ”§ Configuration Guide (é…ç½®æŒ‡å—)

### Essential Configuration Steps (å¿…è¦é…ç½®æ­¥éª¤):

1. **Set Data Path (è®¾ç½®æ•°æ®è·¯å¾„)**
   ```toml
   [paths]
   input_data = "/path/to/your/data.csv"
   output_reports = "/path/to/output/directory"
   ```

2. **Configure Target Analysis (é…ç½®ç›®æ ‡åˆ†æ)**
   ```toml
   [columns]
   # For regression: numeric target
   target_col = "sales_amount"
   
   # For classification: categorical target
   target_col = "customer_category"
   
   # Multiple targets
   target_col = ["target1", "target2"]
   ```

3. **Configure ID Validation (é…ç½®IDéªŒè¯)**
   ```toml
   [columns]
   # Single ID column
   id_cols = ["user_id"]
   
   # Multiple ID columns (composite key)
   id_cols = ["user_id", "session_id", "transaction_id"]
   ```

4. **Adjust Analysis Thresholds (è°ƒæ•´åˆ†æé˜ˆå€¼)**
   ```toml
   [thresholds]
   outlier_threshold = 3.0        # Z-score threshold for outliers
   correlation_threshold = 0.8     # High correlation threshold
   high_cardinality_threshold = 50 # High cardinality threshold
   missing_value_threshold = 0.05  # Missing value concern threshold
   ```

## ğŸ“Š Output Examples (è¾“å‡ºç¤ºä¾‹)

### Statistical Tables (ç»Ÿè®¡è¡¨æ ¼)
```
ğŸ“Š NUMERIC STATISTICS (æ•°å€¼ç»Ÿè®¡)
==================================================

ğŸ“ˆ Basic Statistics (åŸºç¡€ç»Ÿè®¡):
+------------------+----------+
| Metric (æŒ‡æ ‡)    | Value (å€¼) |
+==================+==========+
| Count (è®¡æ•°)     | 10,000   |
| Missing (ç¼ºå¤±å€¼) | 50 (0.5%)|
| Mean (å¹³å‡æ•°)    | 125.45   |
| Median (ä¸­ä½æ•°)  | 120.30   |
+------------------+----------+

ğŸ¯ CORRELATION WITH TARGET (ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§): sales_amount
=============================================================

+----------------+-------------------+------------------+
| Feature (ç‰¹å¾) | Correlation (ç›¸å…³æ€§)| Strength (å¼ºåº¦)  |
+================+===================+==================+
| price         | 0.8234            | Very Strong (å¾ˆå¼º)|
| quantity      | 0.6891            | Strong (å¼º)      |
+----------------+-------------------+------------------+
```

### Report Files Generated (ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶)
- **PowerPoint Report**: Professional presentation with embedded bilingual statistics, target analysis, and ID validation
- **JSON Report**: Complete machine-readable results with formatted statistics sections
- **CSV Summary**: Quick overview table
- **Log File**: Detailed processing information

### Enhanced Report Content (å¢å¼ºæŠ¥å‘Šå†…å®¹)
**All reports now include (æ‰€æœ‰æŠ¥å‘Šç°åœ¨åŒ…æ‹¬):**
- ğŸ“Š **Bilingual Statistics**: English/Chinese labels in all statistical tables
- ğŸ¯ **Target Analysis**: Correlation analysis and distribution insights (if configured)
- ğŸ†” **ID Validation**: Uniqueness checking and duplicate detection (if configured)
- ğŸ’¡ **Enhanced Recommendations**: Comprehensive data cleaning suggestions
- ğŸ“ˆ **Professional Formatting**: Clean, readable presentation suitable for stakeholders

## ğŸ”¬ Advanced Features (é«˜çº§åŠŸèƒ½)

### Target Variable Analysis (ç›®æ ‡å˜é‡åˆ†æ)
- **Correlation Analysis**: Automatically calculates correlations between all features and target variables
- **Distribution Analysis**: Analyzes target distribution for class balance (classification) or normality (regression)
- **Cross-tabulation**: For categorical targets, shows how other categorical variables relate to target classes

### ID Column Validation (IDåˆ—éªŒè¯)
- **Uniqueness Checking**: Validates that ID columns contain unique values
- **Composite Key Support**: Checks uniqueness across multiple ID columns
- **Duplicate Reporting**: Identifies and reports specific duplicate values

### Enhanced Statistics (å¢å¼ºç»Ÿè®¡)
- **Outlier Detection**: Multiple methods (Z-score, IQR, Modified Z-score)
- **Distribution Testing**: Normality tests (Shapiro-Wilk, D'Agostino)
- **Cardinality Analysis**: High cardinality detection for categorical variables

## ğŸ› ï¸ Troubleshooting (æ•…éšœæ’é™¤)

### Common Issues (å¸¸è§é—®é¢˜)

1. **Module Not Found Error**
   ```bash
   # Install missing dependencies
   pip install pandas numpy scipy matplotlib seaborn python-pptx click
   ```

2. **Memory Issues with Large Files**
   ```toml
   [analysis]
   chunk_size = 5000
   max_memory_mb = 512
   ```
   
   ```bash
   # Use sampling for large datasets
   honeyclean stats large_file.csv --sample 10000
   ```

3. **Configuration File Not Found**
   ```bash
   # Create configuration file first
   honeyclean init
   ```

4. **Permission Errors**
   ```bash
   # Check output directory permissions
   mkdir -p ./reports
   chmod 755 ./reports
   ```

## ğŸ“‹ Example Workflow (ç¤ºä¾‹å·¥ä½œæµç¨‹)

### Simple Workflow (ç®€å•å·¥ä½œæµç¨‹) â­ **RECOMMENDED**
```bash
# 1. Initialize project (åˆå§‹åŒ–é¡¹ç›®)
honeyclean init

# 2. Edit base.toml with your data path and target columns
# ç¼–è¾‘ base.tomlï¼Œè®¾ç½®æ•°æ®è·¯å¾„å’Œç›®æ ‡åˆ—

# 3. Run complete analysis (è¿è¡Œå®Œæ•´åˆ†æ)
honeyclean run

# That's it! All analysis, stats, and reports are generated with:
# å®Œæˆï¼æ‰€æœ‰åˆ†æã€ç»Ÿè®¡å’ŒæŠ¥å‘Šéƒ½å·²ç”Ÿæˆï¼ŒåŒ…å«ï¼š
# âœ… Bilingual statistical tables embedded in reports
# âœ… Target correlation analysis (if configured)
# âœ… ID uniqueness validation (if configured)  
# âœ… Professional PowerPoint and JSON reports
```

### Advanced Workflow (é«˜çº§å·¥ä½œæµç¨‹)
```bash
# 1. Initialize and configure (åˆå§‹åŒ–å’Œé…ç½®)
honeyclean init
# Edit base.toml with your settings

# 2. Quick overview without reports (å¿«é€Ÿæ¦‚è§ˆï¼Œæ— æŠ¥å‘Š)
honeyclean stats

# 3. Generate detailed reports (ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š)
honeyclean profile

# 4. Analyze specific problematic columns (åˆ†æç‰¹å®šé—®é¢˜åˆ—)
honeyclean analyze --columns price --columns category

# 5. Complete analysis with custom settings (è‡ªå®šä¹‰è®¾ç½®çš„å®Œæ•´åˆ†æ)
honeyclean run --sample 50000 --output ./final_reports

# 6. Check configuration (æ£€æŸ¥é…ç½®)
honeyclean info
```

## ğŸ¤ Contributing (è´¡çŒ®)

We welcome contributions! Please feel free to:
- Report bugs (æŠ¥å‘Šé”™è¯¯)
- Suggest features (å»ºè®®åŠŸèƒ½)
- Submit pull requests (æäº¤æ‹‰å–è¯·æ±‚)
- Improve documentation (æ”¹è¿›æ–‡æ¡£)

## ğŸ“„ License (è®¸å¯è¯)

This project is licensed under the MIT License.

## ğŸ“ Support (æ”¯æŒ)

For questions and support:
- Create an issue on GitHub
- Check the documentation
- Review example configurations

---

**Happy Data Cleaning! (æ•°æ®æ¸…æ´—æ„‰å¿«ï¼)** ğŸ¯âœ¨